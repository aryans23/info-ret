{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSCE 670 :: Information Storage and Retrieval :: Texas A&M University :: Spring 2018\n",
    "\n",
    "\n",
    "# Homework 3:  Embeddings + Recommenders\n",
    "\n",
    "### 100 points [5% of your final grade]\n",
    "\n",
    "### Due: Monday, April 9 by 11:59pm\n",
    "\n",
    "*Goals of this homework:* There are two main learning objectives: (i) implement and evaluate a pre-cursor to modern word2vec embeddings; and (ii) implement, evaluate, and improve upon traditional collaborative filtering recommenders.\n",
    "\n",
    "*Submission Instructions:* To submit your homework, rename this notebook as UIN_hw#.ipynb. For example, this homework submission would be: YourUIN_hw3.ipynb. Submit this notebook via ecampus. Your notebook should be completely self-contained, with the results visible in the notebook. \n",
    "\n",
    "*Late submission policy:* For this homework, you may use up to three of your late days, meaning that no submissions will be accepted after Thursday, April 12 at 11:59pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Word Embeddings (50 points)\n",
    "For this first part, we're going to implement a word embedding approach that is a bit simpler than word2vec. The key idea is to look at co-occurrences between center words and context words (somewhat like in word2vec) but without any pesky learning of model parameters.\n",
    "\n",
    "If you're interested in a deeper treatment of comparing count vs. learned embeddings, take a look at: [Don’t count, predict! A systematic comparison of\n",
    "context-counting vs. context-predicting semantic vectors](\n",
    "http://www.aclweb.org/anthology/P14-1023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Brown Corpus\n",
    "\n",
    "The dataset for this part is the (in)famous [Brown corpus](https://en.wikipedia.org/wiki/Brown_Corpus) that is a collection of text samples from a wide range of sources, with over one million unique words. Good for us, you can find the Brown corpus in nltk. *Make sure you have already installed nltk with something like: conda install nltk*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have it locally, you can load the dataset into your notebook. You can access the words using brown.words():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "# sents = brown.sents()\n",
    "# sents = list(sents)\n",
    "# sents = [[\"jack marcus done jack marcus jack jack\"]]\n",
    "print(brown.words())\n",
    "bwords = list(brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Dataset Pre-processing\n",
    "OK, now we need to do some basic pre-processing. For this part you should:\n",
    "\n",
    "* Remove stopwords and punctuation.\n",
    "* Make everything lowercase.\n",
    "\n",
    "Then, count how often each word occurs. We will define the 5,000 most  frequent words as your vocabulary (V). We will define the 1,000 most frequent words as our context (C). Include a print statement below to show the top-20 words after pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "words = []\n",
    "for w in bwords:\n",
    "    words.append(str(w).translate(None, string.punctuation).lower())\n",
    "words = [w for w in words if w not in stopwords.words('english') and len(w)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "bag = Counter()\n",
    "bag.update(words)\n",
    "V = [x[0] for x in bag.most_common(5000)]\n",
    "C = [x[0] for x in bag.most_common(1000)]\n",
    "print(bag.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Building the Co-occurrence Matrix \n",
    "\n",
    "For each word in the vocabulary (w), we want to calculate how often context words from C appear in its surrounding window of size 4 (two words before and two words after).\n",
    "\n",
    "In other words, we need to define a co-occurrence matrix that has a dimension of |V|x|C| such that each cell (w,c) represents the number of times c occurs in a window around w. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "import numpy as np\n",
    "\n",
    "vocab_to_index = {word:i for i, word in enumerate(V)}\n",
    "index_to_vocab = {i:word for i, word in enumerate(V)}\n",
    "context_to_index = {word:i for i, word in enumerate(C)}\n",
    "co_occurrence_matrix = np.zeros((len(V), len(C)))\n",
    "\n",
    "n = 5\n",
    "fivegrams = ngrams(words, n)\n",
    "for gram in fivegrams:\n",
    "    gram = list(gram)\n",
    "    central_word = gram[2]\n",
    "    if (central_word not in V):\n",
    "        continue;\n",
    "    for i in np.arange(5):\n",
    "        if (i == 2):\n",
    "            continue\n",
    "        if (gram[i] in C):\n",
    "            co_occurrence_matrix[vocab_to_index[central_word]][context_to_index[gram[i]]] += 1\n",
    "\n",
    "print(co_occurrence_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Probability Distribution\n",
    "\n",
    "Using the co-occurrence matrix, we can compute the probability distribution Pr(c|w) of context word c around w as well as the overall probability distribution of each context word c with Pr(c).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "com = np.array(co_occurrence_matrix)\n",
    "pcw = com/com.sum(axis=1, keepdims=True)\n",
    "pcw[np.isnan(pcw)] = 0     # Making all NaNs to 0\n",
    "# print(pcw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pw = [x[1] for x in bag.most_common(1000)]\n",
    "pw = [float(p)/len(words) for p in pw]\n",
    "# print pw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Embedding Representation\n",
    "\n",
    "Now you can represent each vocabulary word as a |C| dimensional vector using this equation:\n",
    "\n",
    "Vector(w)= max(0, log (Pr(c|w)/Pr(c)))\n",
    "\n",
    "This is a traditional approach called *pointwise mutual information* that pre-dates word2vec by some time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = np.log(pcw/pw)\n",
    "b = embeddings < 0\n",
    "embeddings[b] = 0\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Analysis\n",
    "\n",
    "So now we have some embeddings for each word. But are they meaningful? For this part, you should:\n",
    "\n",
    "- First, cluster the vocabulary into 100 clusters using k-means. Look over the words in each cluster, can you see any relation beween words? Discuss your observations.\n",
    "\n",
    "- Second, for the top-20 most frequent words, find the nearest neighbors using cosine distance (1- cosine similarity). Do the findings make sense? Discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k-means\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=100).fit(embeddings)\n",
    "clusters = []\n",
    "\n",
    "def ClusterIndicesNumpy(clustNum, labels_array):\n",
    "    return np.where(labels_array == clustNum)[0]\n",
    "\n",
    "for i in range(len(kmeans.labels_)):\n",
    "    idx = ClusterIndicesNumpy(i,kmeans.labels_)\n",
    "    clusters.append([index_to_vocab[i] for i in idx])\n",
    "\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nearest neighbors\n",
    "top_20 = [x[0] for x in bag.most_common(20)]\n",
    "# print(top_20)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10,metric='cosine')\n",
    "y = np.arange(embeddings.shape[0])\n",
    "knn.fit(embeddings, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_index = knn.kneighbors(embeddings, return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(nn_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = []\n",
    "for n in nn_index[:20]:\n",
    "    nn.append([index_to_vocab[n[i]] for i in range(1,10)])\n",
    "for i in range(len(nn)):\n",
    "    print(V[i]+\"{}\".format(nn[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Collaborative Filtering (50 points)\n",
    "\n",
    "In this second part, you will implement collaborative filtering on the Netflix prize dataset -- don’t freak out, the provided sample dataset has only ~2000 items and ~28,000 users.\n",
    "\n",
    "As background, read the paper [Empirical Analysis of Predictive Algorithms for Collaborative Filtering](https://arxiv.org/pdf/1301.7363.pdf) up to Section 2.1. Of course you can read further if you are interested, and you can also refer to the course slides for collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Netflix Data\n",
    "\n",
    "The dataset is subset of movie ratings data from the Netflix Prize Challenge. Download the dataset from Piazza. It contains a train set, test set, movie file, and README file. The last two files are original ones from the Netflix Prize, however; in this homework you will deal with train and test files which both are subsets of the Netflix training data. Each of train and test files has lines having this format: MovieID,UserID,Rating.\n",
    "\n",
    "Your job is to predict a rating in the test set using those provided in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Movies in train set = 1821\n",
      "Number of Users in train set = 28978\n",
      "Number of Ratings in train set = 5\n"
     ]
    }
   ],
   "source": [
    "# load the data, then print out the number of ratings, \n",
    "# movies and users in each of train and test sets.\n",
    "# load the data, then print out the number of ratings, \n",
    "# movies and users in each of train and test sets.\n",
    "\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv('netflix-dataset/TrainingRatings.txt', header = None, usecols=[0,1,2])\n",
    "# print(train_df[:10])\n",
    "train_df.columns = ['mid','uid','r']\n",
    "print(\"Number of Movies in train set = \" + str(train_df.loc[:,'mid'].unique().size))\n",
    "print(\"Number of Users in train set = \" + str(train_df.loc[:,'uid'].unique().size))\n",
    "print(\"Number of Ratings in train set = \" + str(train_df.loc[:,'r'].unique().size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Movies in test set = 1701\n",
      "Number of Users in test set = 27555\n",
      "Number of Ratings in test set = 5\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('netflix-dataset/TestingRatings.txt', header = None)\n",
    "# print(test_df[:10])\n",
    "test_df.columns = ['mid','uid','r']\n",
    "print(\"Number of Movies in test set = \" + str(test_df.loc[:,'mid'].unique().size))\n",
    "print(\"Number of Users in test set = \" + str(test_df.loc[:,'uid'].unique().size))\n",
    "print(\"Number of Ratings in test set = \" + str(test_df.loc[:,'r'].unique().size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Implement CF\n",
    "\n",
    "In this part, you will implement the basic collaborative filtering algorithm described in Section 2.1 of the paper -- that is, focus only on Equations 1 and 2 (where Equation 2 is just the Pearson correlation). You should consider the first 5,000 users with their associated items in the test set. \n",
    "\n",
    "Note that you should test the algorithm for a small set of users e.g., 10 users first and then run for 5,000 users. It may take long to run but you won't have memory issues. \n",
    "\n",
    "Set k to 0.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train = train_df.pivot(index='uid',columns='mid',values='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pcor = train.transpose().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uid_train = train.index.values\n",
    "# user_ids_train = {i:j for i,j in zip(uid_train,range(uid_train.size))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mid_train = train.columns.values\n",
    "# movie_ids_train = {i:j for i,j in zip(mid_train,range(mid_train.size))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_ratings = train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_full = test_df.pivot(index='uid',columns='mid',values='r')\n",
    "# test = test_full[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uid_test = test.index.values\n",
    "# user_ids_test = {i:j for i,j in zip(uid_test, range(uid_test.size))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mid_test = test.columns.values\n",
    "# movie_ids_test = {i:j for i,j in zip(mid_test, range(mid_test.size))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vi_avg = train.mean(axis=1).to_dict()\n",
    "# va_avg = test.mean(axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t = test.values\n",
    "# va_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import math\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# k = 0.1\n",
    "# p = np.zeros((uid_test.size, mid_test.size))\n",
    "\n",
    "# for a in uid_test:\n",
    "#     for j in mid_test:\n",
    "#         p[user_ids_test[a]][movie_ids_test[j]] = va_avg[a]\n",
    "#         for i in uid_train:\n",
    "#             corr = pcor[a][i]\n",
    "# #             print user_ids_test[i]\n",
    "# #             print movie_ids_test[j]\n",
    "#             rating_ij = train_ratings[user_ids_train[i]][movie_ids_train[j]]\n",
    "#             if (corr <= 0):\n",
    "#                 continue\n",
    "#             if (math.isnan(rating_ij)): \n",
    "#                 continue\n",
    "#             p[user_ids_test[a]][movie_ids_test[j]] += k*corr*(rating_ij-vi_avg[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Movie:\n",
    "    def __init__(self):\n",
    "        self.average_rating = None\n",
    "        self.ratings = dict({})\n",
    "\n",
    "class User:\n",
    "    def __init__(self):\n",
    "        self.average_rating = None\n",
    "        self.ratings = dict({})\n",
    "        self.norm_avg = None\n",
    "\n",
    "USER_DICT = {}\n",
    "MOVIE_DICT = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take user input for the dataset to train on and the\n",
    "training_set = 'netflix-dataset/TrainingRatings.txt'\n",
    "\n",
    "# Open the training set and pull all of the information into the global dictionaries defined above.\n",
    "with open(training_set, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        # Parse each value from the line.\n",
    "        a = line.rstrip('\\n').split(',')\n",
    "        movie_id = a[0]\n",
    "        user_id = a[1]\n",
    "        rating = float(a[2])\n",
    "\n",
    "        # Add each user to USER_DICT, or update the one we've already made.\n",
    "        if USER_DICT.get(user_id): # User is already in the dictionary, so just update that user.\n",
    "            USER_DICT[user_id].ratings[movie_id] = rating\n",
    "#             USER_DICT[user_id].average_rating = (USER_DICT[user_id].average_rating + rating) / len(USER_DICT[user_id].ratings)\n",
    "#             USER_DICT[user_id].norm_avg = pow((pow(USER_DICT[user_id].norm_avg, 2) + pow(rating, 2)), 0.5)\n",
    "        else: # User is not yet in the dictionary, so let's make one.\n",
    "            USER_DICT[user_id] = User()\n",
    "#             USER_DICT[user_id].average_rating = rating\n",
    "#             USER_DICT[user_id].norm_avg = rating\n",
    "            USER_DICT[user_id].ratings[movie_id] = rating\n",
    "\n",
    "        # Add each movie to MOVIE_DICT, or update the one we've already made.\n",
    "        if MOVIE_DICT.get(movie_id): # Movie is already in the dictionary, so just update the movie.\n",
    "            MOVIE_DICT[movie_id].ratings[user_id] = rating\n",
    "#             MOVIE_DICT[movie_id].average_rating = (MOVIE_DICT[movie_id].average_rating + rating) / len(MOVIE_DICT[movie_id].ratings)\n",
    "        else: # Movie is not yet in the dictionary, so let's make one.\n",
    "            MOVIE_DICT[movie_id] = Movie()\n",
    "#             MOVIE_DICT[movie_id].average_rating = rating\n",
    "            MOVIE_DICT[movie_id].ratings[user_id] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id, val in USER_DICT.items():\n",
    "    USER_DICT[user_id].average_rating = np.mean(np.array(val.ratings.values()))\n",
    "    USER_DICT[user_id].norm_avg = np.linalg.norm(np.array(val.ratings.values()))\n",
    "\n",
    "for movie_id, val in MOVIE_DICT.items():\n",
    "    MOVIE_DICT[movie_id].average_rating = np.mean(np.array(val.ratings.values()))\n",
    "    MOVIE_DICT[movie_id].norm_avg = np.linalg.norm(np.array(val.ratings.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1942739\n",
      "3.27358490566\n",
      "34.7706773014\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for key, val in USER_DICT.items():\n",
    "    if (i == 1):\n",
    "        break\n",
    "    print key\n",
    "    print val.average_rating\n",
    "    print val.norm_avg\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start classifying the data.\n",
    "# testing_set = 'netflix-dataset/TestingRatings.txt'\n",
    "# predicted = []\n",
    "# true = []\n",
    "# k = 0.001\n",
    "\n",
    "# with open(testing_set, 'r') as f:\n",
    "#     lines = f.readlines()\n",
    "#     n = 0 # Keep track of the number of ratings classified.\n",
    "#     mae_sum = 0.0 # Keep track of the sum for the Mean Absolute Error.\n",
    "#     rmse_sum = 0.0 # Keep track of the sum for the Root Mean Squared Error.\n",
    "\n",
    "#     # Use this dictionary to keep track of already calculated weights.\n",
    "#     # This is pretty intense on memory, but it makes the algorithm\n",
    "#     # significantly faster.\n",
    "#     weights = {}\n",
    "\n",
    "#     for line in lines[:100]:\n",
    "#         # Parse the movie_id, user_id, and the actual rating.\n",
    "#         a = line.rstrip('\\n').split(',')\n",
    "#         movie_id = a[0]\n",
    "#         user_id = a[1]\n",
    "#         rating = float(a[2])\n",
    "\n",
    "#         # Only classify id we already have data on the user.\n",
    "#         if user_id in USER_DICT:\n",
    "#             current_user = USER_DICT[user_id] # User we need to predict for.\n",
    "#             avg_rating = current_user.average_rating # That user's average rating.\n",
    "#             sum = 0.0 # Sum for equation 1.\n",
    "\n",
    "#             for key, value in USER_DICT.items(): # Iterate through USER_DICT.\n",
    "#                 # Only calculate a weight if the new user has given a rating to the movie in question.\n",
    "#                 if (key != user_id and movie_id in value.ratings):\n",
    "#                     weight = 0 # Keep track of the weight.\n",
    "#                     # Check if the weight has already been calculated.\n",
    "#                     if (user_id, key) not in weights and (key, user_id) not in weights:\n",
    "#                         # We have to calculate the weight.\n",
    "# #                         num = 0\n",
    "# #                         den = 0\n",
    "#                         for m, rating in value.ratings.items():\n",
    "#                             # For every common movie, update the weight.\n",
    "#                             if m != movie_id and m in current_user.ratings:\n",
    "#                                 weight += (current_user.ratings[m] / current_user.norm_avg) * (rating / value.norm_avg)\n",
    "#                         # Save this weight for later. MEMOIZATION\n",
    "#                         weights[(user_id, key)] = weight\n",
    "#                     else:\n",
    "#                         # The weight has already been calculated. Just pull it.\n",
    "#                         if (user_id, key) in weights:\n",
    "#                             weight = weights[(user_id, key)]\n",
    "#                         elif (key, user_id) in weights:\n",
    "#                             weight = weights[(key, user_id)]\n",
    "#                     # Update sum.\n",
    "#                     sum += weight * (value.ratings[movie_id] - value.average_rating)\n",
    "                    \n",
    "#             calc_rating = avg_rating + k * sum # Here's our predicted rating.\n",
    "#             print(\"sum = \" + str(sum))\n",
    "#             print(\"avg_rating = \" + str(avg_rating))\n",
    "#             print(\"calc_rating = \" + str(calc_rating))\n",
    "\n",
    "#             # If the rating is lower than 1, just clamp it to 1.\n",
    "#             if calc_rating < 1.0:\n",
    "#                 calc_rating = 1.0\n",
    "#             # If the rating is greater than 5, just clamp it to 5.\n",
    "#             elif calc_rating > 5.0:\n",
    "#                 calc_rating = 5.0\n",
    "#             # Otherwise, just round it.\n",
    "#             else:\n",
    "#                 calc_rating = round(calc_rating)\n",
    "\n",
    "#             n += 1 # Increment n.\n",
    "\n",
    "# #             mae_sum += abs(calc_rating - rating) # Update sum for Mean Absolute Error.\n",
    "# #             rmse_sum += pow((calc_rating - rating), 2) # Update sum for Root Mean Squared Error.\n",
    "#             predicted.append(calc_rating)\n",
    "#             true.append(rating)\n",
    "\n",
    "# #     mae = mae_sum / n # Calc MAE\n",
    "# #     rmse = pow((rmse_sum / n), 0.5) # Calc RMSE\n",
    "\n",
    "#     # Print them\n",
    "# #     print(\"The Mean Absolute Error is {0}\".format(mae))\n",
    "# #     print(\"The Root Mean Squared Error is {0}\".format(rmse))\n",
    "#     print(predicted)\n",
    "#     print(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum = -224.612287356\n",
      "avg_rating = 3.48507462687\n",
      "calc_rating = 3.26046233951\n",
      "sum = -196.270952324\n",
      "avg_rating = 3.44\n",
      "calc_rating = 3.24372904768\n",
      "sum = -308.077503466\n",
      "avg_rating = 2.96428571429\n",
      "calc_rating = 2.65620821082\n",
      "sum = -298.78681878\n",
      "avg_rating = 3.24375\n",
      "calc_rating = 2.94496318122\n",
      "sum = -149.794807707\n",
      "avg_rating = 3.10891089109\n",
      "calc_rating = 2.95911608338\n",
      "sum = -278.66397912\n",
      "avg_rating = 3.27848101266\n",
      "calc_rating = 2.99981703354\n",
      "sum = -160.527430382\n",
      "avg_rating = 3.16477272727\n",
      "calc_rating = 3.00424529689\n",
      "sum = -185.431015541\n",
      "avg_rating = 4.05434782609\n",
      "calc_rating = 3.86891681055\n",
      "sum = -96.4590673266\n",
      "avg_rating = 3.70930232558\n",
      "calc_rating = 3.61284325825\n",
      "sum = -164.083772796\n",
      "avg_rating = 3.39\n",
      "calc_rating = 3.2259162272\n",
      "sum = -286.306601172\n",
      "avg_rating = 3.20183486239\n",
      "calc_rating = 2.91552826121\n",
      "sum = -128.237825418\n",
      "avg_rating = 1.18906942393\n",
      "calc_rating = 1.06083159851\n",
      "sum = -251.99668525\n",
      "avg_rating = 3.05882352941\n",
      "calc_rating = 2.80682684416\n",
      "sum = 0.0\n",
      "avg_rating = 1.0\n",
      "calc_rating = 1.0\n",
      "sum = -302.564485575\n",
      "avg_rating = 4.02912621359\n",
      "calc_rating = 3.72656172802\n",
      "sum = -350.368842213\n",
      "avg_rating = 3.54666666667\n",
      "calc_rating = 3.19629782445\n",
      "sum = -110.561056355\n",
      "avg_rating = 3.3768115942\n",
      "calc_rating = 3.26625053785\n",
      "sum = -202.440063701\n",
      "avg_rating = 3.30952380952\n",
      "calc_rating = 3.10708374582\n",
      "sum = -301.955120752\n",
      "avg_rating = 3.46153846154\n",
      "calc_rating = 3.15958334079\n",
      "sum = -289.680331439\n",
      "avg_rating = 3.27586206897\n",
      "calc_rating = 2.98618173753\n",
      "sum = -267.037928961\n",
      "avg_rating = 4.19277108434\n",
      "calc_rating = 3.92573315538\n",
      "sum = -324.963565123\n",
      "avg_rating = 3.5390070922\n",
      "calc_rating = 3.21404352708\n",
      "sum = -255.043588194\n",
      "avg_rating = 4.19736842105\n",
      "calc_rating = 3.94232483286\n",
      "sum = -360.033614376\n",
      "avg_rating = 3.47368421053\n",
      "calc_rating = 3.11365059615\n",
      "sum = -229.165657833\n",
      "avg_rating = 4.27631578947\n",
      "calc_rating = 4.04715013164\n",
      "sum = -259.927983674\n",
      "avg_rating = 3.19587628866\n",
      "calc_rating = 2.93594830499\n",
      "sum = -23.9862963363\n",
      "avg_rating = 3.88888888889\n",
      "calc_rating = 3.86490259255\n",
      "sum = -130.082796625\n",
      "avg_rating = 3.32911392405\n",
      "calc_rating = 3.19903112743\n",
      "sum = -231.548981827\n",
      "avg_rating = 3.74074074074\n",
      "calc_rating = 3.50919175891\n",
      "sum = -187.956075678\n",
      "avg_rating = 2.65853658537\n",
      "calc_rating = 2.47058050969\n",
      "sum = -237.201733161\n",
      "avg_rating = 2.94642857143\n",
      "calc_rating = 2.70922683827\n",
      "sum = -213.090554515\n",
      "avg_rating = 3.63414634146\n",
      "calc_rating = 3.42105578695\n",
      "sum = -186.642400851\n",
      "avg_rating = 3.12096774194\n",
      "calc_rating = 2.93432534108\n",
      "sum = -154.309880653\n",
      "avg_rating = 2.95833333333\n",
      "calc_rating = 2.80402345268\n",
      "sum = -191.105207308\n",
      "avg_rating = 3.85915492958\n",
      "calc_rating = 3.66804972227\n",
      "sum = -104.739911211\n",
      "avg_rating = 4.45945945946\n",
      "calc_rating = 4.35471954825\n",
      "sum = 28.2429380387\n",
      "avg_rating = 3.93582887701\n",
      "calc_rating = 3.96407181504\n",
      "sum = -124.351995549\n",
      "avg_rating = 3.47647058824\n",
      "calc_rating = 3.35211859269\n",
      "sum = -303.987329039\n",
      "avg_rating = 3.74782608696\n",
      "calc_rating = 3.44383875792\n",
      "sum = 13.4502256215\n",
      "avg_rating = 3.30714285714\n",
      "calc_rating = 3.32059308276\n",
      "sum = -196.270148053\n",
      "avg_rating = 3.70476190476\n",
      "calc_rating = 3.50849175671\n",
      "sum = -340.848699712\n",
      "avg_rating = 3.98701298701\n",
      "calc_rating = 3.6461642873\n",
      "sum = -292.150976308\n",
      "avg_rating = 3.32\n",
      "calc_rating = 3.02784902369\n",
      "sum = -231.698992239\n",
      "avg_rating = 3.69879518072\n",
      "calc_rating = 3.46709618848\n",
      "sum = -29.4043407896\n",
      "avg_rating = 3.22972972973\n",
      "calc_rating = 3.20032538894\n",
      "sum = -200.652443608\n",
      "avg_rating = 3.90410958904\n",
      "calc_rating = 3.70345714543\n",
      "sum = -285.372464158\n",
      "avg_rating = 3.26495726496\n",
      "calc_rating = 2.9795848008\n",
      "sum = -143.450839473\n",
      "avg_rating = 2.71084337349\n",
      "calc_rating = 2.56739253402\n",
      "sum = -214.241679671\n",
      "avg_rating = 3.33333333333\n",
      "calc_rating = 3.11909165366\n",
      "sum = -264.697149434\n",
      "avg_rating = 3.38805970149\n",
      "calc_rating = 3.12336255206\n",
      "sum = -35.9825159173\n",
      "avg_rating = 3.02752293578\n",
      "calc_rating = 2.99154041986\n",
      "sum = -239.086792323\n",
      "avg_rating = 3.54545454545\n",
      "calc_rating = 3.30636775313\n",
      "sum = -175.663740564\n",
      "avg_rating = 3.93617021277\n",
      "calc_rating = 3.7605064722\n",
      "sum = -259.654159887\n",
      "avg_rating = 4.03174603175\n",
      "calc_rating = 3.77209187186\n",
      "sum = -133.429150881\n",
      "avg_rating = 4.04081632653\n",
      "calc_rating = 3.90738717565\n",
      "sum = -185.309100568\n",
      "avg_rating = 3.75\n",
      "calc_rating = 3.56469089943\n",
      "sum = -224.030054678\n",
      "avg_rating = 3.57692307692\n",
      "calc_rating = 3.35289302225\n",
      "sum = -31.1608280906\n",
      "avg_rating = 3.82978723404\n",
      "calc_rating = 3.79862640595\n",
      "sum = -312.07833439\n",
      "avg_rating = 3.31818181818\n",
      "calc_rating = 3.00610348379\n",
      "sum = 29.0059828497\n",
      "avg_rating = 3.10112359551\n",
      "calc_rating = 3.13012957836\n",
      "sum = -186.8218956\n",
      "avg_rating = 3.29166666667\n",
      "calc_rating = 3.10484477107\n",
      "sum = -115.734395559\n",
      "avg_rating = 4.20224719101\n",
      "calc_rating = 4.08651279545\n",
      "sum = -113.962092997\n",
      "avg_rating = 3.61437908497\n",
      "calc_rating = 3.50041699197\n",
      "sum = -181.172022373\n",
      "avg_rating = 3.37362637363\n",
      "calc_rating = 3.19245435125\n",
      "sum = -220.404097119\n",
      "avg_rating = 3.33628318584\n",
      "calc_rating = 3.11587908872\n",
      "sum = -321.495117865\n",
      "avg_rating = 3.62992125984\n",
      "calc_rating = 3.30842614198\n",
      "sum = -7.05724301124\n",
      "avg_rating = 3.46451612903\n",
      "calc_rating = 3.45745888602\n",
      "sum = -288.535832958\n",
      "avg_rating = 2.92253521127\n",
      "calc_rating = 2.63399937831\n",
      "sum = -116.749747185\n",
      "avg_rating = 3.925\n",
      "calc_rating = 3.80825025282\n",
      "sum = -204.883274366\n",
      "avg_rating = 3.41721854305\n",
      "calc_rating = 3.21233526868\n",
      "sum = -174.832112912\n",
      "avg_rating = 4.34545454545\n",
      "calc_rating = 4.17062243254\n",
      "sum = -285.084419521\n",
      "avg_rating = 3.52336448598\n",
      "calc_rating = 3.23828006646\n",
      "sum = -130.35479407\n",
      "avg_rating = 2.61481481481\n",
      "calc_rating = 2.48446002074\n",
      "sum = -348.957852809\n",
      "avg_rating = 3.06896551724\n",
      "calc_rating = 2.72000766443\n",
      "sum = -215.285544251\n",
      "avg_rating = 4.17307692308\n",
      "calc_rating = 3.95779137883\n",
      "sum = -237.060342554\n",
      "avg_rating = 3.49572649573\n",
      "calc_rating = 3.25866615317\n",
      "sum = -287.969905376\n",
      "avg_rating = 3.55974842767\n",
      "calc_rating = 3.2717785223\n",
      "sum = -246.261627088\n",
      "avg_rating = 4.17045454545\n",
      "calc_rating = 3.92419291837\n",
      "sum = -292.452504719\n",
      "avg_rating = 3.01204819277\n",
      "calc_rating = 2.71959568805\n",
      "sum = -50.1500074589\n",
      "avg_rating = 3.73333333333\n",
      "calc_rating = 3.68318332587\n",
      "sum = -247.165693696\n",
      "avg_rating = 3.75423728814\n",
      "calc_rating = 3.50707159444\n",
      "sum = -242.74432329\n",
      "avg_rating = 3.25510204082\n",
      "calc_rating = 3.01235771753\n",
      "sum = -252.815640454\n",
      "avg_rating = 3.59183673469\n",
      "calc_rating = 3.33902109424\n",
      "sum = -315.613414883\n",
      "avg_rating = 3.24444444444\n",
      "calc_rating = 2.92883102956\n",
      "sum = -199.395726706\n",
      "avg_rating = 3.1652173913\n",
      "calc_rating = 2.9658216646\n",
      "sum = -91.7301257157\n",
      "avg_rating = 3.71052631579\n",
      "calc_rating = 3.61879619007\n",
      "sum = -163.0014827\n",
      "avg_rating = 3.97413793103\n",
      "calc_rating = 3.81113644833\n",
      "sum = -108.108097711\n",
      "avg_rating = 4.64\n",
      "calc_rating = 4.53189190229\n",
      "sum = -117.700928632\n",
      "avg_rating = 3.77456647399\n",
      "calc_rating = 3.65686554536\n",
      "sum = -283.783254942\n",
      "avg_rating = 4.0\n",
      "calc_rating = 3.71621674506\n",
      "sum = -296.553291759\n",
      "avg_rating = 3.77333333333\n",
      "calc_rating = 3.47678004157\n",
      "sum = -249.797066966\n",
      "avg_rating = 2.42857142857\n",
      "calc_rating = 2.1787743616\n",
      "sum = -201.120698638\n",
      "avg_rating = 2.72727272727\n",
      "calc_rating = 2.52615202863\n",
      "sum = -131.323168208\n",
      "avg_rating = 3.44791666667\n",
      "calc_rating = 3.31659349846\n",
      "sum = -227.625477747\n",
      "avg_rating = 3.53571428571\n",
      "calc_rating = 3.30808880797\n",
      "sum = -71.0948259843\n",
      "avg_rating = 3.77777777778\n",
      "calc_rating = 3.70668295179\n",
      "sum = 337.706234628\n",
      "avg_rating = 3.37254901961\n",
      "calc_rating = 3.71025525424\n",
      "sum = 391.453404067\n",
      "avg_rating = 3.7380952381\n",
      "calc_rating = 4.12954864216\n",
      "sum = 608.644264184\n",
      "avg_rating = 2.98666666667\n",
      "calc_rating = 3.59531093085\n",
      "sum = 467.090708204\n",
      "avg_rating = 3.88741721854\n",
      "calc_rating = 4.35450792675\n",
      "[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 3.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 4.0, 3.0, 4.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 5.0, 4.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0]\n",
      "[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "# Start classifying the data.\n",
    "testing_set = 'netflix-dataset/TestingRatings.txt'\n",
    "predicted = []\n",
    "true = []\n",
    "k = 0.001\n",
    "\n",
    "with open(testing_set, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    n = 0 # Keep track of the number of ratings classified.\n",
    "    mae_sum = 0.0 # Keep track of the sum for the Mean Absolute Error.\n",
    "    rmse_sum = 0.0 # Keep track of the sum for the Root Mean Squared Error.\n",
    "\n",
    "    # Use this dictionary to keep track of already calculated weights.\n",
    "    # This is pretty intense on memory, but it makes the algorithm\n",
    "    # significantly faster.\n",
    "    weights = {}\n",
    "\n",
    "    for line in lines[:100]:\n",
    "        # Parse the movie_id, user_id, and the actual rating.\n",
    "        a = line.rstrip('\\n').split(',')\n",
    "        movie_id = a[0]\n",
    "        user_id = a[1]\n",
    "        rating = float(a[2])\n",
    "\n",
    "        # Only classify id we already have data on the user.\n",
    "        if user_id in USER_DICT:\n",
    "            current_user = USER_DICT[user_id] # User we need to predict for.\n",
    "            avg_rating = current_user.average_rating # That user's average rating.\n",
    "            sum = 0.0 # Sum for equation 1.\n",
    "\n",
    "            for key, value in USER_DICT.items(): # Iterate through USER_DICT.\n",
    "                # Only calculate a weight if the new user has given a rating to the movie in question.\n",
    "                if (key != user_id and movie_id in value.ratings):\n",
    "                    weight = 0 # Keep track of the weight.\n",
    "                    # Check if the weight has already been calculated.\n",
    "                    if (user_id, key) not in weights and (key, user_id) not in weights:\n",
    "                        # We have to calculate the weight.\n",
    "                        num = 0\n",
    "                        d1 = 0\n",
    "                        d2 = 0\n",
    "                        for m, rating in value.ratings.items():\n",
    "                            # For every common movie, update the weight.\n",
    "                            if m != movie_id and m in current_user.ratings:\n",
    "                                num += (current_user.ratings[m]-current_user.average_rating)*(rating-value.average_rating) \n",
    "                        for m, rating in value.ratings.items():\n",
    "                            # For every common movie, update the weight.\n",
    "                            if m != movie_id and m in current_user.ratings:\n",
    "                                d1 += pow((current_user.ratings[m]-current_user.average_rating),2)\n",
    "                                d2 += pow((rating-value.average_rating),2)\n",
    "                        if (d1 == 0 or d2 == 0):\n",
    "                            continue\n",
    "                        weight = num/pow((d1*d2),0.5)\n",
    "                            \n",
    "                        # Save this weight for later. MEMOIZATION\n",
    "                        weights[(user_id, key)] = weight\n",
    "                    else:\n",
    "                        # The weight has already been calculated. Just pull it.\n",
    "                        if (user_id, key) in weights:\n",
    "                            weight = weights[(user_id, key)]\n",
    "                        elif (key, user_id) in weights:\n",
    "                            weight = weights[(key, user_id)]\n",
    "                    # Update sum.\n",
    "                    sum += weight * (value.ratings[movie_id] - value.average_rating)\n",
    "                    \n",
    "            calc_rating = avg_rating + k * sum # Here's our predicted rating.\n",
    "            print(\"sum = \" + str(sum))\n",
    "            print(\"avg_rating = \" + str(avg_rating))\n",
    "            print(\"calc_rating = \" + str(calc_rating))\n",
    "\n",
    "            # If the rating is lower than 1, just clamp it to 1.\n",
    "            if calc_rating < 1.0:\n",
    "                calc_rating = 1.0\n",
    "            # If the rating is greater than 5, just clamp it to 5.\n",
    "            elif calc_rating > 5.0:\n",
    "                calc_rating = 5.0\n",
    "            # Otherwise, just round it.\n",
    "            else:\n",
    "                calc_rating = round(calc_rating)\n",
    "\n",
    "            n += 1 # Increment n.\n",
    "\n",
    "            predicted.append(calc_rating)\n",
    "            true.append(rating)\n",
    "\n",
    "    print(predicted)\n",
    "    print(true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Evaluation \n",
    "\n",
    "You should evaluate your predictions using Mean Absolute Error and Root Mean Squared Error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40999999999999998"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(true, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46999999999999997"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Root Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(true, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Extensions\n",
    "\n",
    "Given your results in the previous part, can you do better? For this last part you should report on your best attempt at improving MAE and RMSE. Provide code, results, plus a brief discussion on your approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Insert discussion here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
